{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PedrohPerini/Desafio2_MachineLearning/blob/main/Desafio1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importa a biblioteca TensorFlow, que é uma biblioteca de aprendizado de máquina.\n",
        "import tensorflow as tf\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "mINvb7MgFzEL"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPKxtr_IFEfO",
        "outputId": "ce7fc632-cddb-483e-9e62-964c46bb4fd9"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_dados = pd.read_csv('/content/drive/MyDrive/german-credit-data.csv', encoding = 'utf 8')"
      ],
      "metadata": {
        "id": "pWICvd0QFX1O"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dados.drop(index=[0, 1], inplace=True)"
      ],
      "metadata": {
        "id": "POrjNtF-MYB0"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dados"
      ],
      "metadata": {
        "collapsed": true,
        "id": "T17eMYU4Lpcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dados = base_dados.drop(columns = ['Crédito'])\n",
        "alvo = base_dados['Crédito']"
      ],
      "metadata": {
        "id": "2CgsNnsFM750"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importa a função `train_test_split` do scikit-learn, que é usada para dividir o dataset em conjuntos de treinamento e teste.\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(dados, alvo, test_size=0.20, random_state=42)"
      ],
      "metadata": {
        "id": "ZSUiDEFLGz_0"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importa a função `train_test_split` do scikit-learn, que é usada para dividir o dataset em conjuntos de treinamento e teste.\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Converte as colunas com strings em representações numéricas usando one-hot encoding\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "encoder = OneHotEncoder(handle_unknown='ignore')\n",
        "x_train = encoder.fit_transform(x_train)\n",
        "x_test = encoder.transform(x_test)\n",
        "\n",
        "# Converte 'Bom' para 1 e 'Ruim' para 0 na variável alvo\n",
        "y_train = y_train.map({'Bom': 1, 'Ruim': 0})\n",
        "y_test = y_test.map({'Bom': 1, 'Ruim': 0})\n",
        "\n",
        "# Cria um modelo sequencial do TensorFlow Keras.\n",
        "# O modelo é uma sequência de camadas aplicadas umas após as outras.\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(128, activation=tf.nn.relu, input_shape=(x_train.shape[1],)), # Adiciona input_shape\n",
        "  tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Treina o modelo com os dados de treinamento.\n",
        "# `epochs=50` indica que o modelo passará pelos dados de treinamento 50 vezes.\n",
        "model.fit(x_train, y_train, epochs=50)\n",
        "\n",
        "# Avalia o modelo com os dados de teste para verificar seu desempenho.\n",
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "C95W4GYfUf3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "puK5BSmXsi3g"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Faz previsões no conjunto de teste.\n",
        "previsoes_prob = model.predict(x_test)\n",
        "\n",
        "# Converte as probabilidades previstas em rótulos de classe.\n",
        "previsoes = np.argmax(previsoes_prob, axis=1)\n",
        "\n",
        "# Calcula a matriz de confusão.\n",
        "matrix = confusion_matrix(y_test, previsoes)\n",
        "\n",
        "print(matrix)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}